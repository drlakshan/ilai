---
tags:
  - AI
  - ethics
aliases:
---
2025-10-26

# What Did I learn?


There is a notion that we need to know how the AI models think because we may not understand the decision-making processes and that may have consequences.  

even the inventors of this large language models don’t know what exactly goes through in these algorithms and that is the concept of black box 

however, now it’s clear that  human neural networks also are behaving like blackboxes. 

So the black box theory of us not knowing clearly what's going on in large language model thought processes may not be that of a problem because that happens all the time with human thinking as well.







# Context:






## References





## Related

[[AI Creativity - AlphaGo's Move 37 and AlphaFold's Breakthroughs]]

[[All models are wrong some are useful]]

# tags





