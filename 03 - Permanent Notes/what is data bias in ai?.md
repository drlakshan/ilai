
This is a bias arising from the training dataset itself





Data bias is a circumstance in which systemic errors or prejudices lead to unfair or inaccurate information, resulting in biased outputs.

- **Example:** Let's say you're training an AI model to recognize images of doctors. If the training dataset primarily consists of images of male doctors, the AI might incorrectly assume that most doctors are male and be less accurate in identifying female doctors. This demonstrates how a skewed dataset can lead to biased results. 

[[Representational bias in AI]]
